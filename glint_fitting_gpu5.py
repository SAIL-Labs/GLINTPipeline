# -*- coding: utf-8 -*-
"""
Created on Thu Mar 14 15:44:07 2019

@author: mamartinod

Fit model of pdf over measured Na PDF

Requirements:
    - measured values of Na
    - measured values of photometries
    - measured values of dark noise
    - gaussian distribution of phase
    
To do:
    - generate random values from arbitrary PDF for photometries
    - generate random values from arbitrary PDF for dark current
    - compute a sample of Null values from the previous rv
    - create the histogram to fit to the measured Null PDF
"""

import numpy as np
import cupy as cp
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit, least_squares
from timeit import default_timer as time
import h5py
import os
import sys
import glint_fitting_functions5 as gff
from scipy.special import erf
from scipy.io import loadmat
from scipy.stats import norm, skewnorm
import pickle
from datetime import datetime


def MCfunction(bins0, na, mu_opd, sig_opd):
    '''
    For now, this function deals with polychromatic for one baseline
    '''
    # Imported in the funcion
    global data_IA_axis, cdf_data_IA, data_IB_axis, cdf_data_IB, spectra # On GPU
    global zeta_minus_A, zeta_minus_B, zeta_plus_A, zeta_plus_B
    global dark_Iminus_cdf, dark_Iminus_axis, dark_Iplus_cdf, dark_Iplus_axis # On GPU
    global spec_chan_width
    
    # generated by the function
    global rv_IA, rv_IB, rv_opd, rv_dark_Iminus, rv_dark_Iplus, rv_null, rv_interfminus, rv_interfplus, interfminus, interfplus # On GPU
    global phase_bias, bins

    # Parameters of the MC process
    global n_samp, count, wl_scale0, nloop 
    global oversampling_switch, switch_invert_null
    global fichier
    global rv_IA_list

    count += 1
    print(int(count), na, mu_opd, sig_opd)
    try:
        fichier.write('%s\t%s\t%s\t%s\n'%(int(count), na, mu_opd, sig_opd))
    except:
        pass
    
    accum = cp.zeros((bins0.shape[0], bins0.shape[1]-1), dtype=cp.float32) # Axes: spectral channel, number of bins

    
    if wl_scale0.size > 1:
        spec_chan_width = np.mean(np.diff(wl_scale0))
    
        
    ''' Number of samples to simulate is high and the memory is low so we iterate to create an average histogram '''
    for _ in range(nloop):
        rv_opd = cp.random.normal(mu_opd, sig_opd, n_samp)
        rv_opd = rv_opd.astype(cp.float32)
#        rv_opd = skewnorm.rvs(skew, loc=mu_opd, scale=sig_opd, size=n_samp) # Skewd Gaussian distribution
#        rv_opd = cp.asarray(rv_opd, dtype=cp.float32) # Load the random values into the graphic card
        
        if activate_spectral_binning:
            interfminus_binned, interfplus_binned = cp.zeros(n_samp, dtype=cp.float32), cp.zeros(n_samp, dtype=cp.float32)
        
        # Generate random values of injection
        rv_injectionA = gff.rv_generator(data_IA_axis, cdf_data_IA, n_samp)   # random values for photometry A         
        rv_injectionB = gff.rv_generator(data_IB_axis, cdf_data_IB, n_samp) # random values for photometry B
        
        # Reconstruct the spectrum
        rv_IA = rv_injectionA[None,:] * cp.asarray(spectra[0], dtype=cp.float32)[:,None]
        rv_IB = rv_injectionB[None,:] * cp.asarray(spectra[0], dtype=cp.float32)[:,None]
        
        for k in range(wl_scale0.size): # Iterate over the wavelength axis
#            bin_width = cp.mean(cp.diff(bins), dtype=cp.float32)
            # random values for dark noise
            rv_dark_Iminus = gff.rv_generator(dark_Iminus_axis[k], dark_Iminus_cdf[k], n_samp)
            rv_dark_Iminus = rv_dark_Iminus.astype(cp.float32)
            rv_dark_Iplus = gff.rv_generator(dark_Iplus_axis[k], dark_Iplus_cdf[k], n_samp)
            rv_dark_Iplus = rv_dark_Iplus.astype(cp.float32)
            # rv_dark_Iminus -= rv_dark_Iminus.mean()
            # rv_dark_Iplus -= rv_dark_Iplus.mean()            
            
            rv_IA = rv_injectionA * spectra[0][k]
            rv_IB = rv_injectionB * spectra[1][k]
            
            # Random values for synthetic null depths
#            rv_null, rv_interfminus, rv_interfplus = gff.computeNullDepthLinear(na, rv_IA, rv_IB, wl_scale0[k], rv_opd, phase_bias, dphase_bias, rv_dark_Iminus, rv_dark_Iplus, 
#                     zeta_minus_A[k], zeta_minus_B[k], zeta_plus_A[k], zeta_plus_B[k],
#                     spec_chan_width, oversampling_switch, switch_invert_null)
            rv_null, rv_interfminus, rv_interfplus = gff.computeNullDepth(na, rv_IA, rv_IB, wl_scale0[k], rv_opd, phase_bias, dphase_bias, rv_dark_Iminus, rv_dark_Iplus, 
                     zeta_minus_A[k], zeta_minus_B[k], zeta_plus_A[k], zeta_plus_B[k],
                     spec_chan_width, oversampling_switch, switch_invert_null)
            
            if activate_spectral_binning:
                interfminus_binned += rv_interfminus
                interfplus_binned += rv_interfplus
            else:
                rv_null = rv_null[~np.isnan(rv_null)] # Remove NaNs
                rv_null = cp.sort(rv_null)
                
                ''' Compute the average histogram over the nloops iterations '''
                bins = cp.asarray(bins0[k], dtype=cp.float32)
                pdf_null = cp.histogram(rv_null, bins)[0]
                accum[k] += pdf_null / cp.sum(pdf_null)#*bin_width)

        if activate_spectral_binning: 
            interfminus_binned = interfminus_binned / wl_scale0.size
            interfplus_binned = interfplus_binned / wl_scale0.size
            if switch_invert_null:
                rv_null_binned = interfplus_binned / interfminus_binned
            else:
                rv_null_binned = interfminus_binned / interfplus_binned

            rv_null = rv_null[~np.isnan(rv_null)] # Remove NaNs
            rv_null = cp.sort(rv_null)                
            pdf_null = cp.histogram(rv_null, cp.asarray(bins0[0], dtype=cp.float32))[0]
            accum[0] += pdf_null / cp.sum(pdf_null)#*bin_width)
        
    accum = accum / nloop
    if cp.all(cp.isnan(accum)):
        accum[:] = 0
    accum = cp.asnumpy(accum)

    return accum.ravel()

class Logger(object):
    ''' Class allowing to save the content of the console inside a txt file '''
    def __init__(self, log_path):
        self.orig_stdout = sys.stdout
        self.terminal = sys.stdout
        self.log = open(log_path, "a")

    def write(self, message):
        self.terminal.write(message)
        self.log.write(message)  

    def flush(self):
        #this flush method is needed for python 3 compatibility.
        #this handles the flush command by doing nothing.
        #you might want to specify some extra behavior here.
        pass
    
    def close(self):
        sys.stdout = self.orig_stdout
        self.log.close()
        print('Stdout closed')

def basin_hoppin_values(mu_opd0, sig_opd0, na0, bounds_mu, bounds_sig, bounds_na):
    ''' Create as many as initial guess as there are basin hopping iterations to do'''

#    orig_seed = np.random.get_state()
#    np.random.seed(1)
    print('Random drawing of init guesses')
    
    for _ in range(1000):
        mu_opd = np.random.normal(mu_opd0, 10)
        if mu_opd > bounds_mu[0] and mu_opd < bounds_mu[1]:
            break
        if _ == 1000-1:
            print('mu_opd: no new guess, take initial one')
            mu_opd = mu_opd0
    
    for _ in range(1000):
        sig_opd = abs(np.random.normal(sig_opd0, 10))
        if sig_opd > bounds_sig[0] and sig_opd < bounds_sig[1]:
            break
        if _ == 1000-1:
            print('sig opd: no new guess, take initial one')
            sig_opd = sig_opd0
        
    for _ in range(1000):
        na = np.random.normal(na0, 0.005)
        if na > bounds_na[0] and na < bounds_na[1]:
            break
        if _ == 1000-1:
            print('na: no new guess, take initial one')
            na = na0
            
    print('Random drawing done')
#    np.random.set_state(orig_seed)
    return mu_opd, sig_opd, na
        
step = 3000
nbfiles = 30000  # Omi Cet
#nbfiles = 36000 # Eps Peg
#nbfiles = 3300 # Turbulence 1
nb_files_data0 = np.arange(0, nbfiles, step)
#nb_files_data0 = np.tile(nb_files_data0 , 10) # Turbulence 1
basin_hopping_nloop0 = np.arange(nb_files_data0.size)
nb_files_data1 = nb_files_data0[:1]
basin_hopping_nloop1 = basin_hopping_nloop0[:1]


for a, b in zip(basin_hopping_nloop1, nb_files_data1):
    ''' Settings '''  
    wl_min = 1525 # lower bound of the bandwidth to process
    wl_max = 1575 # Uppber bound of the bandwidth to process
    wl_mid = (wl_max + wl_min)/2 # Centre wavelength of the bandwidth
    spec_chan_width = 50 # Width of the band, useful if you integrate over a bandwidth to compute the measure null. Set the width of the integrated spectral band then
    n_samp = int(1e+5) # number of samples per loop
    nloop = 10
    mode = 'cuda' # Mode for using the MC method, let as 'cuda'
    phase_bias_switch = True # Implement a non-null achromatic phase in the null model
    opd_bias_switch = True # Implement an offset OPD in the null model
    zeta_switch = True # Use the measured zeta coeff. If False, value are set to 1
    oversampling_switch = True # Include the loss of coherence when OPD is too far from 0, according to a sinc envelop
    skip_fit = False # Do not fit, plot the histograms of data and model given the initial guesses
    chi2_map_switch = False # Map the parameters space over astronull, DeltaPhi mu and sigma
    nb_files_data = (None, None) #(0, 20781) #(0, 20781) #(20782, None) # Which data files to load
    nb_files_dark = (0, None) # Which dark files to load
    basin_hopping_nloop = (a, a+1) # lower and upper bound of the iteration loop for basin hopping method
    activate_random_init_guesses = True
    activate_spectral_binning = False
    
    if not skip_fit and not chi2_map_switch:
        plt.close('all')

##    # =============================================================================
#    # NullerData_SubaruJuly2019/20190718/20190718_turbulence1/ - 50 nm
#    # =============================================================================
#    ''' Set the bounds of the parameters to fit '''
#    nulls_to_invert = [''] # If one null and antinull outputs are swapped in the data processing
#    nulls_to_invert_model = [''] # If one null and antinull outputs are swapped in the data processing
#    bounds_mu0  = [(0, 400),      (2200, 2500), (2200, 2500), (0, 600),      (3000, 3500), (0, 700)] # bounds for DeltaPhi mu, one tuple per null
#    bounds_sig0 = [(100, 300),    (200, 300),   (200, 300),   (50,250),      (50, 600),  (100, 400)] # bounds for DeltaPhi sig
#    bounds_na0  = [(-0.1, 0.1),   (-0.2, 0.2),  (-0.2, 0.2),  (-0.01, 0.01), (-0.025, 0.025), (-0.01, 0.01)] # bounds for astronull
##    bounds_sig0 = [(100, 300),    (200, 300),   (200, 300),   (50,300),      (50, 600),  (100, 400)] # 1271
##    bounds_na0  = [(-0.1, 0.1),   (-0.2, 0.2),  (-0.2, 0.2),  (-0.01, 0.02), (-0.025, 0.025), (-0.01, 0.01)] # 1271
##    bounds_mu0[4] = (-6600, -5900)
##    bounds_sig0[4] = (200, 500)
#    diffstep = [0.001, 10, 10] # differential step to apply to the TRF fitting algorithm, used for computing the finite difference
#    xscale = np.ones(len(diffstep)) # scale factor of the parameters to fit, see least_squares doc for more details
#    bin_bounds0 = [(-0.02, 0.6), (-0.1, 0.4), (-0.1, 0.4), (-0.02, 0.6), (-0.02, 0.4), (-0.02, 1.)] # Boundaries of the histogram, to be set manually after checking the histogram sphape with "skip_fit = True"
##    bin_bounds0 = [(-0.2, 0.6), (-0.1, 0.4), (-0.1, 0.4), (-0.2, 0.6), (-0.02, 0.4), (-0.02, 1.)] # 1271 ron
##    bin_bounds0 = [(-0.1, 0.6), (-0.1, 0.4), (-0.1, 0.4), (-0.1, 0.6), (-0.02, 0.4), (-0.02, 1.)] # 459 ron
#    
#    ''' Set the initial conditions '''
#    mu_opd0 = np.array([200, 2400, 2400, 300, 3200, 400]) # initial guess of DeltaPhi mu
#    sig_opd0 = np.array([200, 260, 260, 150, 200, 250]) # initial guess of DeltaPhi sig
#    na0 = np.array([0, 0, 0, 0, 0, 0]) # initial guess of astro null
#    
#    ''' Import real data '''
#    datafolder = 'NullerData_SubaruJuly2019/20190718/20190718_turbulence1_50nm_offset/'
#    darkfolder = 'NullerData_SubaruJuly2019/20190718/20190718_dark_turbulence_50nm_offset/'
##    root = "//silo.physics.usyd.edu.au/silo4/snert/"
#    root = "C:/Users/marc-antoine/glint/"
#    file_path = root+'GLINTprocessed/'+datafolder
#    save_path = file_path+'output/'
#    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'n1n4' in f][nb_files_data[0]:nb_files_data[1]]
##    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'n5n6' in f][nb_files_data[0]:nb_files_data[1]]
#    dark_list = [root+'GLINTprocessed/'+darkfolder+f for f in os.listdir(root+'GLINTprocessed/'+darkfolder) if '.hdf5' in f and 'dark' in f][nb_files_dark[0]:nb_files_dark[1]]

#    # =============================================================================
#    # NullerData_SubaruJuly2019/20190718/20190718_turbulence2/ - 50 nm
#    # =============================================================================
#    ''' Set the bounds of the parameters to fit '''
#    nulls_to_invert = [''] # If one null and antinull outputs are swapped in the data processing
#    nulls_to_invert_model = [''] # If one null and antinull outputs are swapped in the data processing
#    bounds_mu0  = [(0, 400),      (2200, 2500), (2200, 2500), (0, 600), (3000, 4000), (0, 700)] # bounds for DeltaPhi mu, one tuple per null
#    bounds_sig0 = [(50, 300),    (200, 300),   (200, 300),   (50,200),      (50, 450),  (50, 400)] # bounds for DeltaPhi sig
#    bounds_na0  = [(-0.1, 0.1),   (-0.2, 0.2),  (-0.2, 0.2),  (-0.01, 0.01), (-0.01, 0.01), (-0.01, 0.01)] # bounds for astronull
##    bounds_mu0[4] = (-6600, -5900)
##    bounds_sig0[4] = (200, 500)
#    diffstep = [0.001, 10, 10] # differential step to apply to the TRF fitting algorithm, used for computing the finite difference
#    xscale = np.ones(len(diffstep)) # scale factor of the parameters to fit, see least_squares doc for more details
#    bin_bounds0 = [(-0.02, 0.6), (-0.1, 0.4), (-0.1, 0.4), (-0.02, 0.6), (-0.02, 0.4), (-0.02, 1.)] # Boundaries of the histogram, to be set manually after checking the histogram sphape with "skip_fit = True"
#    
#    ''' Set the initial conditions '''
#    mu_opd0 = np.array([200, 2400, 2400, 300, 3700, 400]) # initial guess of DeltaPhi mu
#    sig_opd0 = np.array([200, 260, 260, 150, 200, 250]) # initial guess of DeltaPhi sig
#    na0 = np.array([0, 0, 0, 0, 0, 0]) # initial guess of astro null
#    
#    ''' Import real data '''
#    datafolder = 'NullerData_SubaruJuly2019/20190718/20190718_turbulence2_50nm_offset/'
#    darkfolder = 'NullerData_SubaruJuly2019/20190718/20190718_dark_turbulence_50nm_offset/'
##    root = "//silo.physics.usyd.edu.au/silo4/snert/"
#    root = "C:/Users/marc-antoine/glint/"
#    file_path = root+'GLINTprocessed/'+datafolder
#    save_path = file_path+'output/'
##    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'n1n4' in f][nb_files_data[0]:nb_files_data[1]]
#    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'n5n6' in f][nb_files_data[0]:nb_files_data[1]]
#    dark_list = [root+'GLINTprocessed/'+darkfolder+f for f in os.listdir(root+'GLINTprocessed/'+darkfolder) if '.hdf5' in f and 'dark' in f][nb_files_dark[0]:nb_files_dark[1]]

#    # =============================================================================m
#    # NullerData_SubaruJuly2019/20190718/20190718_turbulence3/ - 50 nm
#    # =============================================================================
#    ''' Set the bounds of the parameters to fit '''
#    nulls_to_invert = [''] # If one null and antinull outputs are swapped in the data processing
#    nulls_to_invert_model = [''] # If one null and antinull outputs are swapped in the data processing
#    bounds_mu0  = [(0, 400),      (2200, 2500), (2200, 2500), (0, 400), (3000, 3500), (0, 700)] # bounds for DeltaPhi mu, one tuple per null
#    bounds_sig0 = [(50, 150),    (200, 300),   (200, 300),   (50,150),      (50, 150),  (100, 200)] # bounds for DeltaPhi sig
#    bounds_na0  = [(-0.1, 0.1),   (-0.2, 0.2),  (-0.2, 0.2),  (-0.01, 0.01), (-0.01, 0.01), (-0.01, 0.01)] # bounds for astronull
##    bounds_mu0[4] = (-6600, -5900)
##    bounds_sig0[4] = (200, 500)
#    diffstep = [0.001, 10, 10] # differential step to apply to the TRF fitting algorithm, used for computing the finite difference
#    xscale = np.ones(len(diffstep)) # scale factor of the parameters to fit, see least_squares doc for more details
#    bin_bounds0 = [(-0.02, 0.3), (-0.1, 0.4), (-0.1, 0.4), (-0.02, 0.4), (-0.02, 0.2), (-0.02, 0.4)] # Boundaries of the histogram, to be set manually after checking the histogram sphape with "skip_fit = True"
#    
#    ''' Set the initial conditions '''
#    mu_opd0 = np.array([200, 2400, 2400, 300, 3300, 400]) # initial guess of DeltaPhi mu
#    sig_opd0 = np.array([100, 260, 260, 100, 120, 140]) # initial guess of DeltaPhi sig
#    na0 = np.array([0, 0, 0, 0, 0, 0]) # initial guess of astro null
#    
#    ''' Import real data '''
#    datafolder = 'NullerData_SubaruJuly2019/20190718/20190718_turbulence3_50nm_offset/'
#    darkfolder = 'NullerData_SubaruJuly2019/20190718/20190718_dark_turbulence_50nm_offset/'
##    root = "//silo.physics.usyd.edu.au/silo4/snert/"
#    root = "C:/Users/marc-antoine/glint/"
#    file_path = root+'GLINTprocessed/'+datafolder
#    save_path = file_path+'output/'
#    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'n1n4' in f][nb_files_data[0]:nb_files_data[1]]
##    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'n5n6' in f][nb_files_data[0]:nb_files_data[1]]
#    dark_list = [root+'GLINTprocessed/'+darkfolder+f for f in os.listdir(root+'GLINTprocessed/'+darkfolder) if '.hdf5' in f and 'dark' in f][nb_files_dark[0]:nb_files_dark[1]]

#    # =============================================================================
#    # NullerData_SubaruJuly2019/20190718/20190718_turbulence4/ - 50 nm
#    # =============================================================================
#    ''' Set the bounds of the parameters to fit '''
#    nulls_to_invert = [''] # If one null and antinull outputs are swapped in the data processing
#    nulls_to_invert_model = [''] # If one null and antinull outputs are swapped in the data processing
#    bounds_mu0  = [(0, 400),      (2200, 2500), (2200, 2500), (0, 600), (3000, 4000), (0, 600)] # bounds for DeltaPhi mu, one tuple per null
#    bounds_sig0 = [(50, 300),    (200, 300),   (200, 300),   (50,200),      (100, 400),  (50, 200)] # bounds for DeltaPhi sig
#    bounds_na0  = [(-0.1, 0.1),   (-0.2, 0.2),  (-0.2, 0.2),  (-0.01, 0.01), (-0.05, 0.05), (-0.01, 0.01)] # bounds for astronull
##    bounds_mu0[4] = (-6600, -5900)
##    bounds_sig0[4] = (200, 500)
#    diffstep = [0.001, 10, 10] # differential step to apply to the TRF fitting algorithm, used for computing the finite difference
#    xscale = np.ones(len(diffstep)) # scale factor of the parameters to fit, see least_squares doc for more details
#    bin_bounds0 = [(-0.02, 0.4), (-0.1, 0.4), (-0.1, 0.4), (-0.02, 0.6), (-0.01, 0.2), (-0.02, 0.4)] # Boundaries of the histogram, to be set manually after checking the histogram sphape with "skip_fit = True"
#    
#    ''' Set the initial conditions '''
#    mu_opd0 = np.array([200, 2400, 2400, 300, 3700, 400]) # initial guess of DeltaPhi mu
#    sig_opd0 = np.array([200, 260, 260, 150, 150, 100]) # initial guess of DeltaPhi sig
#    na0 = np.array([0, 0, 0, 0, 0, 0]) # initial guess of astro null
#    
#    ''' Import real data '''
#    datafolder = 'NullerData_SubaruJuly2019/20190718/20190718_turbulence4_50nm_offset/'
#    darkfolder = 'NullerData_SubaruJuly2019/20190718/20190718_dark_turbulence_50nm_offset/'
##    root = "//silo.physics.usyd.edu.au/silo4/snert/"
#    root = "C:/Users/marc-antoine/glint/"
#    file_path = root+'GLINTprocessed/'+datafolder
#    save_path = file_path+'output/'
##    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'n1n4' in f][nb_files_data[0]:nb_files_data[1]]
#    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'n5n6' in f][nb_files_data[0]:nb_files_data[1]]
#    dark_list = [root+'GLINTprocessed/'+darkfolder+f for f in os.listdir(root+'GLINTprocessed/'+darkfolder) if '.hdf5' in f and 'dark' in f][nb_files_dark[0]:nb_files_dark[1]]

#    # =============================================================================
#    # NullerData_SubaruJuly2019/20190718/20190718_turbulence5/ - 50 nm
#    # =============================================================================
#    ''' Set the bounds of the parameters to fit '''
#    nulls_to_invert = [''] # If one null and antinull outputs are swapped in the data processing
#    nulls_to_invert_model = [''] # If one null and antinull outputs are swapped in the data processing
#    bounds_mu0  = [(0, 800),      (2200, 2500), (2200, 2500), (0, 600), (3000, 4000), (0, 600)] # bounds for DeltaPhi mu, one tuple per null
#    bounds_sig0 = [(100, 300),    (200, 300),   (200, 300),   (50,200),      (50, 250),  (50, 200)] # bounds for DeltaPhi sig
#    bounds_na0  = [(-0.01, 0.01),   (-0.2, 0.2),  (-0.2, 0.2),  (-0.01, 0.01), (-0.05, 0.05), (-0.01, 0.01)] # bounds for astronull
##    bounds_mu0[4] = (-6600, -5900)
##    bounds_sig0[4] = (200, 500)
#    diffstep = [0.001, 10, 10] # differential step to apply to the TRF fitting algorithm, used for computing the finite difference
#    xscale = np.ones(len(diffstep)) # scale factor of the parameters to fit, see least_squares doc for more details
#    bin_bounds0 = [(-0.01, 0.1), (-0.1, 0.4), (-0.1, 0.4), (-0.01, 0.3), (-0.01, 0.2), (-0.01, 0.2)] # Boundaries of the histogram, to be set manually after checking the histogram sphape with "skip_fit = True"
#    
#    ''' Set the initial conditions '''
#    mu_opd0 = np.array([200, 2400, 2400, 300, 3600, 400]) # initial guess of DeltaPhi mu
#    sig_opd0 = np.array([200, 260, 260, 150, 100, 100]) # initial guess of DeltaPhi sig
#    na0 = np.array([0, 0, 0, 0, 0, 0]) # initial guess of astro null
#    
#    ''' Import real data '''
#    datafolder = 'NullerData_SubaruJuly2019/20190718/20190718_turbulence5_50nm_offset/'
#    darkfolder = 'NullerData_SubaruJuly2019/20190718/20190718_dark_turbulence_50nm_offset/'
##    root = "//silo.physics.usyd.edu.au/silo4/snert/"
#    root = "C:/Users/marc-antoine/glint/"
#    file_path = root+'GLINTprocessed/'+datafolder
#    save_path = file_path+'output/'
##    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'n1n4' in f][nb_files_data[0]:nb_files_data[1]]
#    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'n5n6' in f][nb_files_data[0]:nb_files_data[1]]
#    dark_list = [root+'GLINTprocessed/'+darkfolder+f for f in os.listdir(root+'GLINTprocessed/'+darkfolder) if '.hdf5' in f and 'dark' in f][nb_files_dark[0]:nb_files_dark[1]]

    # =============================================================================
    # NullerData_SubaruJuly2019/20190718/20190718_turbulence1/
    # =============================================================================
    ''' Set the bounds of the parameters to fit '''
    nulls_to_invert = [''] # If one null and antinull outputs are swapped in the data processing
    nulls_to_invert_model = [''] # If one null and antinull outputs are swapped in the data processing
    bounds_mu0  = [(0, 400),      (2200, 2500), (2200, 2500), (0, 600), (4500, 5000), (0, 700)] # bounds for DeltaPhi mu, one tuple per null
    bounds_sig0 = [(100, 300),    (200, 300),   (200, 300),   (10,200),      (100, 500),  (100, 400)] # bounds for DeltaPhi sig
#    bounds_sig0 = [(100, 400),    (200, 300),   (200, 300),   (50,300),      (100, 500),  (100, 400)] # ron 1271
    bounds_na0  = [(-0.01, 0.01),   (-0.2, 0.2),  (-0.2, 0.2),  (-0.01, 0.01), (-0.05, 0.05), (-0.01, 0.01)] # bounds for astronull
#    bounds_mu0[4] = (-6600, -5900)
#    bounds_sig0[4] = (200, 500)
    diffstep = [0.001, 10, 10] # differential step to apply to the TRF fitting algorithm, used for computing the finite difference
    xscale = np.ones(len(diffstep)) # scale factor of the parameters to fit, see least_squares doc for more details
    bin_bounds0 = [(-0.02, 0.2), (-0.1, 0.4), (-0.1, 0.4), (-0.02, 0.3), (-0.02, 0.1), (-0.02, 0.2)] # Boundaries of the histogram, to be set manually after checking the histogram sphape with "skip_fit = True"
#    bin_bounds0 = [(-0.25, 1), (-0.1, 0.4), (-0.1, 0.4), (-0.25, 1), (-0.02, 0.1), (-0.02, 0.2)] # 459
#    bin_bounds0 = [(-0.6, 1.2), (-0.1, 0.4), (-0.1, 0.4), (-0.6, 1.2), (-0.02, 0.1), (-0.02, 0.2)] # 1271
    
    ''' Set the initial conditions '''
    mu_opd0 = np.array([200, 2400, 2400, 400, 4700, 400]) # initial guess of DeltaPhi mu
    sig_opd0 = np.array([200, 260, 260, 160, 300, 250]) # initial guess of DeltaPhi sig
    na0 = np.array([0., 0, 0, 0, 0, 0]) # initial guess of astro null
    
    ''' Import real data '''
    datafolder = 'NullerData_SubaruJuly2019/20190718/20190718_turbulence1/'
    darkfolder = 'NullerData_SubaruJuly2019/20190718/20190718_dark_turbulence/'
#    root = "//silo.physics.usyd.edu.au/silo4/snert/"
    root = "C:/Users/marc-antoine/glint/"
    root = "/mnt/96980F95980F72D3/glint/"
    file_path = root+'GLINTprocessed/'+datafolder
    save_path = file_path+'output/'
    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'n1n4' in f][nb_files_data[0]:nb_files_data[1]]
#    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'n5n6' in f][nb_files_data[0]:nb_files_data[1]]
    dark_list = [root+'GLINTprocessed/'+darkfolder+f for f in os.listdir(root+'GLINTprocessed/'+darkfolder) if '.hdf5' in f and 'dark' in f][nb_files_dark[0]:nb_files_dark[1]]

#    # =============================================================================
#    # NullerData_SubaruJuly2019/20190718/20190718_turbulence2/
#    # =============================================================================
#    ''' Set the bounds of the parameters to fit '''
#    nulls_to_invert = [''] # If one null and antinull outputs are swapped in the data processing
#    nulls_to_invert_model = [''] # If one null and antinull outputs are swapped in the data processing
#    bounds_mu0  = [(0, 400),      (2200, 2500), (2200, 2500), (0, 600), (4500, 5500), (0, 700)] # bounds for DeltaPhi mu, one tuple per null
#    bounds_sig0 = [(100, 300),    (200, 300),   (200, 300),   (10,200),      (100, 500),  (100, 400)] # bounds for DeltaPhi sig
#    bounds_na0  = [(-0.01, 0.01),   (-0.2, 0.2),  (-0.2, 0.2),  (-0.01, 0.01), (-0.05, 0.05), (-0.01, 0.01)] # bounds for astronull
##    bounds_mu0[4] = (-6600, -5900)
##    bounds_sig0[4] = (200, 500)
#    diffstep = [0.001, 10, 10] # differential step to apply to the TRF fitting algorithm, used for computing the finite difference
#    xscale = np.ones(len(diffstep)) # scale factor of the parameters to fit, see least_squares doc for more details
#    bin_bounds0 = [(-0.02, 0.2), (-0.1, 0.4), (-0.1, 0.4), (-0.02, 0.3), (-0.02, 0.1), (-0.02, 0.2)] # Boundaries of the histogram, to be set manually after checking the histogram sphape with "skip_fit = True"
#    
#    ''' Set the initial conditions '''
#    mu_opd0 = np.array([200, 2400, 2400, 400, 4700, 400]) # initial guess of DeltaPhi mu
#    sig_opd0 = np.array([200, 260, 260, 160, 300, 250]) # initial guess of DeltaPhi sig
#    na0 = np.array([0, 0, 0, 0, 0, 0]) # initial guess of astro null
#    
#    ''' Import real data '''
#    datafolder = 'NullerData_SubaruJuly2019/20190718/20190718_turbulence2/'
#    darkfolder = 'NullerData_SubaruJuly2019/20190718/20190718_dark_turbulence/'
##    root = "//silo.physics.usyd.edu.au/silo4/snert/"
#    root = "C:/Users/marc-antoine/glint/"
#    file_path = root+'GLINTprocessed/'+datafolder
#    save_path = file_path+'output/'
#    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'n1n4' in f][nb_files_data[0]:nb_files_data[1]]
##    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'n5n6' in f][nb_files_data[0]:nb_files_data[1]]
#    dark_list = [root+'GLINTprocessed/'+darkfolder+f for f in os.listdir(root+'GLINTprocessed/'+darkfolder) if '.hdf5' in f and 'dark' in f][nb_files_dark[0]:nb_files_dark[1]]

#    # =============================================================================
#    # NullerData_SubaruJuly2019/20190718/20190718_turbulence3/
#    # =============================================================================
#    ''' Set the bounds of the parameters to fit '''
#    nulls_to_invert = [''] # If one null and antinull outputs are swapped in the data processing
#    nulls_to_invert_model = [''] # If one null and antinull outputs are swapped in the data processing
#    bounds_mu0  = [(0, 400),      (2200, 2500), (2200, 2500), (0, 600), (4500, 5500), (0, 700)] # bounds for DeltaPhi mu, one tuple per null
#    bounds_sig0 = [(100, 300),    (200, 300),   (200, 300),   (10,200),      (100, 500),  (100, 400)] # bounds for DeltaPhi sig
#    bounds_na0  = [(-0.01, 0.01),   (-0.2, 0.2),  (-0.2, 0.2),  (-0.01, 0.01), (-0.05, 0.05), (-0.01, 0.01)] # bounds for astronull
##    bounds_mu0[4] = (-6600, -5900)
##    bounds_sig0[4] = (200, 500)
#    diffstep = [0.001, 10, 10] # differential step to apply to the TRF fitting algorithm, used for computing the finite difference
#    xscale = np.ones(len(diffstep)) # scale factor of the parameters to fit, see least_squares doc for more details
#    bin_bounds0 = [(-0.02, 0.2), (-0.1, 0.4), (-0.1, 0.4), (-0.02, 0.3), (-0.02, 0.1), (-0.02, 0.2)] # Boundaries of the histogram, to be set manually after checking the histogram sphape with "skip_fit = True"
#    
#    ''' Set the initial conditions '''
#    mu_opd0 = np.array([200, 2400, 2400, 400, 4700, 400]) # initial guess of DeltaPhi mu
#    sig_opd0 = np.array([200, 260, 260, 160, 300, 250]) # initial guess of DeltaPhi sig
#    na0 = np.array([0, 0, 0, 0, 0, 0]) # initial guess of astro null
#    
#    ''' Import real data '''
#    datafolder = 'NullerData_SubaruJuly2019/20190718/20190718_turbulence3/'
#    darkfolder = 'NullerData_SubaruJuly2019/20190718/20190718_dark_turbulence/'
##    root = "//silo.physics.usyd.edu.au/silo4/snert/"
#    root = "C:/Users/marc-antoine/glint/"
#    file_path = root+'GLINTprocessed/'+datafolder
#    save_path = file_path+'output/'
##    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'n1n4' in f][nb_files_data[0]:nb_files_data[1]]
#    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'n5n6' in f][nb_files_data[0]:nb_files_data[1]]
#    dark_list = [root+'GLINTprocessed/'+darkfolder+f for f in os.listdir(root+'GLINTprocessed/'+darkfolder) if '.hdf5' in f and 'dark' in f][nb_files_dark[0]:nb_files_dark[1]]

#    # =============================================================================
#    # NullerData_SubaruJuly2019/20190718/20190718_turbulence4/
#    # =============================================================================
#    ''' Set the bounds of the parameters to fit '''
#    nulls_to_invert = [''] # If one null and antinull outputs are swapped in the data processing
#    nulls_to_invert_model = [''] # If one null and antinull outputs are swapped in the data processing
#    bounds_mu0  = [(0, 400),      (2200, 2500), (2200, 2500), (0, 600), (4500, 5500), (0, 700)] # bounds for DeltaPhi mu, one tuple per null
#    bounds_sig0 = [(100, 300),    (200, 300),   (200, 300),   (10,200),      (100, 500),  (100, 400)] # bounds for DeltaPhi sig
#    bounds_na0  = [(-0.01, 0.01),   (-0.2, 0.2),  (-0.2, 0.2),  (-0.01, 0.01), (-0.05, 0.05), (-0.01, 0.01)] # bounds for astronull
##    bounds_mu0[4] = (-6600, -5900)
##    bounds_sig0[4] = (200, 500)
#    diffstep = [0.001, 10, 10] # differential step to apply to the TRF fitting algorithm, used for computing the finite difference
#    xscale = np.ones(len(diffstep)) # scale factor of the parameters to fit, see least_squares doc for more details
#    bin_bounds0 = [(-0.02, 0.2), (-0.1, 0.4), (-0.1, 0.4), (-0.02, 0.3), (-0.02, 0.1), (-0.02, 0.2)] # Boundaries of the histogram, to be set manually after checking the histogram sphape with "skip_fit = True"
#    
#    ''' Set the initial conditions '''
#    mu_opd0 = np.array([200, 2400, 2400, 400, 4700, 400]) # initial guess of DeltaPhi mu
#    sig_opd0 = np.array([200, 260, 260, 160, 300, 250]) # initial guess of DeltaPhi sig
#    na0 = np.array([0, 0, 0, 0, 0, 0]) # initial guess of astro null
#    
#    ''' Import real data '''
#    datafolder = 'NullerData_SubaruJuly2019/20190718/20190718_turbulence4/'
#    darkfolder = 'NullerData_SubaruJuly2019/20190718/20190718_dark_turbulence/'
##    root = "//silo.physics.usyd.edu.au/silo4/snert/"
#    root = "C:/Users/marc-antoine/glint/"
#    file_path = root+'GLINTprocessed/'+datafolder
#    save_path = file_path+'output/'
#    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'n1n4' in f][nb_files_data[0]:nb_files_data[1]]
##    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'n5n6' in f][nb_files_data[0]:nb_files_data[1]]
#    dark_list = [root+'GLINTprocessed/'+darkfolder+f for f in os.listdir(root+'GLINTprocessed/'+darkfolder) if '.hdf5' in f and 'dark' in f][nb_files_dark[0]:nb_files_dark[1]]

#    # =============================================================================
#    # NullerData_SubaruJuly2019/20190718/20190718_turbulence5/
#    # =============================================================================
#    ''' Set the bounds of the parameters to fit '''
#    nulls_to_invert = [''] # If one null and antinull outputs are swapped in the data processing
#    nulls_to_invert_model = [''] # If one null and antinull outputs are swapped in the data processing
#    bounds_mu0  = [(0, 400),      (2200, 2500), (2200, 2500), (0, 600), (5000, 5500), (0, 700)] # bounds for DeltaPhi mu, one tuple per null
#    bounds_sig0 = [(100, 300),    (200, 300),   (200, 300),   (10,200),      (50, 150),  (100, 400)] # bounds for DeltaPhi sig
#    bounds_na0  = [(-0.01, 0.01),   (-0.2, 0.2),  (-0.2, 0.2),  (-0.01, 0.01), (-0.01, 0.01), (-0.01, 0.01)] # bounds for astronull
##    bounds_mu0[4] = (-6600, -5900)
##    bounds_sig0[4] = (200, 500)
#    diffstep = [0.001, 10, 10] # differential step to apply to the TRF fitting algorithm, used for computing the finite difference
#    xscale = np.ones(len(diffstep)) # scale factor of the parameters to fit, see least_squares doc for more details
#    bin_bounds0 = [(-0.02, 0.2), (-0.1, 0.4), (-0.1, 0.4), (-0.02, 0.3), (-0.02, 0.1), (-0.02, 0.2)] # Boundaries of the histogram, to be set manually after checking the histogram sphape with "skip_fit = True"
#    
#    ''' Set the initial conditions '''
#    mu_opd0 = np.array([200, 2400, 2400, 400, 5100, 400]) # initial guess of DeltaPhi mu
#    sig_opd0 = np.array([200, 260, 260, 160, 100, 250]) # initial guess of DeltaPhi sig
#    na0 = np.array([0, 0, 0, 0, 0, 0]) # initial guess of astro null
#    
#    ''' Import real data '''
#    datafolder = 'NullerData_SubaruJuly2019/20190718/20190718_turbulence5/'
#    darkfolder = 'NullerData_SubaruJuly2019/20190718/20190718_dark_turbulence/'
##    root = "//silo.physics.usyd.edu.au/silo4/snert/"
#    root = "C:/Users/marc-antoine/glint/"
#    file_path = root+'GLINTprocessed/'+datafolder
#    save_path = file_path+'output/'
##    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'n1n4' in f][nb_files_data[0]:nb_files_data[1]]
#    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'n5n6' in f][nb_files_data[0]:nb_files_data[1]]
#    dark_list = [root+'GLINTprocessed/'+darkfolder+f for f in os.listdir(root+'GLINTprocessed/'+darkfolder) if '.hdf5' in f and 'dark' in f][nb_files_dark[0]:nb_files_dark[1]]

#    # =============================================================================
#    # NullerData_SubaruJuly2019/20190718/20190718_turbulence2/
#    # =============================================================================
#    ''' Set the bounds of the parameters to fit '''
#    nulls_to_invert = [''] # If one null and antinull outputs are swapped in the data processing
#    nulls_to_invert_model = [''] # If one null and antinull outputs are swapped in the data processing
#    bounds_mu0  = [(-wl_mid, wl_mid),      (2200, 2500), (2200, 2500), (0, 600), (4500, 5000), (0, 700)] # bounds for DeltaPhi mu, one tuple per null
#    bounds_sig0 = [(50, 300),    (200, 300),   (200, 300),   (50,200),      (50, 500),  (50, 400)] # bounds for DeltaPhi sig
#    bounds_na0  = [(-0.1, 0.1),   (-0.2, 0.2),  (-0.2, 0.2),  (-0.01, 0.01), (-0.05, 0.05), (-0.01, 0.01)] # bounds for astronull
##    bounds_mu0[4] = (-6600, -5900)
##    bounds_sig0[4] = (200, 500)
#    diffstep = [0.001, 10, 10] # differential step to apply to the TRF fitting algorithm, used for computing the finite difference
#    xscale = np.ones(len(diffstep)) # scale factor of the parameters to fit, see least_squares doc for more details
#    bin_bounds0 = [(-0.02, 0.6), (-0.1, 0.4), (-0.1, 0.4), (-0.02, 0.6), (-0.02, 0.4), (-0.02, 1.)] # Boundaries of the histogram, to be set manually after checking the histogram sphape with "skip_fit = True"
#    
#    ''' Set the initial conditions '''
#    mu_opd0 = np.array([200, 2400, 2400, 300, 4700, 400]) # initial guess of DeltaPhi mu
#    sig_opd0 = np.array([200, 260, 260, 150, 300, 250]) # initial guess of DeltaPhi sig
#    na0 = np.array([0, 0, 0, 0, 0, 0]) # initial guess of astro null
#    
#    ''' Import real data '''
#    datafolder = 'NullerData_SubaruJuly2019/20190718/20190718_turbulence2/'
#    darkfolder = 'NullerData_SubaruJuly2019/20190718/20190718_dark_turbulence/'
##    root = "//silo.physics.usyd.edu.au/silo4/snert/"
#    root = "C:/Users/marc-antoine/glint/"
#    file_path = root+'GLINTprocessed/'+datafolder
#    save_path = file_path+'output/'
#    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'n1n4' in f][nb_files_data[0]:nb_files_data[1]]
##    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'n5n6' in f][nb_files_data[0]:nb_files_data[1]]
#    dark_list = [root+'GLINTprocessed/'+darkfolder+f for f in os.listdir(root+'GLINTprocessed/'+darkfolder) if '.hdf5' in f and 'dark' in f][nb_files_dark[0]:nb_files_dark[1]]

    ## =============================================================================
    ## 20191128/turbulence/  - Null1 is inverted, null4 is ok
    ## =============================================================================
    #''' Set the bounds of the parameters to fit '''
    #bounds_mu0 = [(0, 600), (2200, 2500), (2200, 2500), (1554/4-300, 1554/4+300), (2200, 2500), (2200, 2500)] # bounds for DeltaPhi mu, one tuple per null
    #bounds_sig0 = [(50, 500), (200, 300), (200, 300), (50,150), (50, 247), (200, 300)] # bounds for DeltaPhi sig
    #bounds_na0 = [(-0.2, 0.2), (0., 0.05), (0., 0.01), (-0.05, 0.05), (0., 0.05), (0., 0.05)] # bounds for astronull
    #diffstep = [0.02, 50, 50] # differential step to apply to the TRF fitting algorithm, used for computing the finite difference
    #xscale = np.ones(len(diffstep)) # scale factor of the parameters to fit, see least_squares doc for more details
    #
    #''' Set the initial conditions '''
    #mu_opd0 = np.array([100, 2400, 2400, 1554/4, 2300, 2300]) # initial guess of DeltaPhi mu
    #sig_opd0 = np.array([180, 260, 260, 100, 200, 201]) # initial guess of DeltaPhi sig
    #na0 = np.array([0., 0.001, 0.001, 0.04, 0.001, 0.001]) # initial guess of astro null
    #
    #datafolder = '20191128/turbulence/'
    #darkfolder = '20191128/dark_turbulence/'
    #root = "C:/Users/marc-antoine/glint/"
    ##root = "/mnt/96980F95980F72D3/glint/"
    #file_path = root+'GLINTprocessed/'+datafolder
    #save_path = file_path+'output/'
    #data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f][nb_files_data[0]:nb_files_data[1]]
    #dark_list = [root+'GLINTprocessed/'+darkfolder+f for f in os.listdir(root+'GLINTprocessed/'+darkfolder) if '.hdf5' in f and 'dark' in f][nb_files_dark[0]:nb_files_dark[1]]
    
#    # =============================================================================
#    # 20191128/turbulence/  - 50nm - Null1 is inverted, null4 is ok
#    # =============================================================================
#    ''' Set the bounds of the parameters to fit '''
#    bounds_mu0 = [(-400, 1000), (2200, 2500), (2200, 2500), (0, 1000), (2200, 2500), (2200, 2500)] # bounds for DeltaPhi mu, one tuple per null
#    bounds_sig0 = [(50, 500), (200, 300), (200, 300), (50,150), (50, 500), (200, 300)] # bounds for DeltaPhi sig
#    bounds_na0 = [(-0.2, 0.2), (0., 0.05), (0., 0.01), (-0.2, 0.2), (0., 0.05), (0., 0.05)] # bounds for astronull
#    diffstep = [0.02, 50, 50] # differential step to apply to the TRF fitting algorithm, used for computing the finite difference
#    xscale = np.ones(len(diffstep)) # scale factor of the parameters to fit, see least_squares doc for more details
#    
#    ''' Set the initial conditions '''
#    mu_opd0 = np.array([100, 2400, 2400, 1554/4, 2300, 2300]) # initial guess of DeltaPhi mu
#    sig_opd0 = np.array([180, 260, 260, 100, 200, 201]) # initial guess of DeltaPhi sig
#    na0 = np.array([0.01, 0.001, 0.001, 0.04, 0.001, 0.001]) # initial guess of astro null
#    
#    datafolder = '20191128/turbulence1554/'
#    darkfolder = '20191128/dark_turbulence1554/'
#    root = "C:/Users/marc-antoine/glint/"
#    #root = "/mnt/96980F95980F72D3/glint/"
#    file_path = root+'GLINTprocessed/'+datafolder
#    save_path = file_path+'output/'
#    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f][nb_files_data[0]:nb_files_data[1]]
#    dark_list = [root+'GLINTprocessed/'+darkfolder+f for f in os.listdir(root+'GLINTprocessed/'+darkfolder) if '.hdf5' in f and 'dark' in f][nb_files_dark[0]:nb_files_dark[1]]
    
#    # =============================================================================
#    # omi cet - Null1 is inverted, null4 is ok
#    # =============================================================================
#    nulls_to_invert = ['null1'] # If one null and antinull outputs are swapped in the data processing
#    nulls_to_invert_model = ['null1'] # If one null and antinull outputs are swapped in the data processing
#    ''' Set the bounds of the parameters to fit '''
#    bounds_mu0 = [(400, 1000), (2200, 2500), (2200, 2500), (0, 400), (-9100, -8000), (4000, 5300)] # bounds for DeltaPhi mu, one tuple per null
#    bounds_sig0 = [(100, 500), (200, 300), (200, 300), (40,140), (100, 500), (100, 400)] # bounds for DeltaPhi sig
#    bounds_na0 = [(0.1, 0.4), (0., 0.05), (0., 0.01), (0., 0.06), (0., 0.1), (0.1, 0.3)] # bounds for astronull
#    diffstep = [0.001, 10, 10] # differential step to apply to the TRF fitting algorithm, used for computing the finite difference
#    xscale = np.ones(len(diffstep)) # scale factor of the parameters to fit, see least_squares doc for more details
#    bin_bounds0 = [(-0.5, 1.5), (-0.1, 0.4), (-0.1, 0.4), (-0.5, 1.), (-0.2, 0.5), (-0.1, 1.)] # Boundaries of the histogram, to be set manually after checking the histogram sphape with "skip_fit = True"
#    
#    ''' Set the initial conditions '''
#    mu_opd0 = np.array([600, 2400, 2400, 200, -8500, 5000]) # initial guess of DeltaPhi mu
#    sig_opd0 = np.array([250, 260, 260, 50, 300, 250]) # initial guess of DeltaPhi sig
#    na0 = np.array([0.3, 0.001, 0.001, 0.04, 0.06, 0.16]) # initial guess of astro null
#    
#    ''' Import real data '''
#    datafolder = '20190907/omi_cet/'
#    darkfolder = '20190907/dark/'
#    root = "//silo.physics.usyd.edu.au/silo4/snert/"
#    #root = "/mnt/96980F95980F72D3/glint/"
#    file_path = root+'GLINTprocessed/'+datafolder
#    save_path = file_path+'output/'
#    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'omi_cet' in f][nb_files_data[0]:nb_files_data[1]]
#    dark_list = [root+'GLINTprocessed/'+darkfolder+f for f in os.listdir(root+'GLINTprocessed/'+darkfolder) if '.hdf5' in f and 'dark' in f][nb_files_dark[0]:nb_files_dark[1]]
    
#     # =============================================================================
#     # omi cet - 50 nm - Null1 is inverted, null4 is ok
#     # =============================================================================
#     nulls_to_invert = ['null1'] # If one null and antinull outputs are swapped in the data processing
#     nulls_to_invert_model = ['null1'] # If one null and antinull outputs are swapped in the data processing
#     ''' Set the bounds of the parameters to fit '''
#     bounds_mu0 = [(50, 500), (2200, 2500), (2200, 2500), (0, wl_mid/4), (-400, 300), (4280, 5200)] # bounds for DeltaPhi mu, one tuple per null
#     bounds_sig0 = [(100, 500), (200, 300), (200, 300), (50,150), (100, 500), (100, 400)] # bounds for DeltaPhi sig
#     bounds_na0 = [(0., 0.35), (0., 0.05), (0., 0.01), (0.0, 0.2), (0.0, 0.1), (0.1, 0.3)] # bounds for astronull
# #    bounds_mu0[4] = (-6600, -5900)
# #    bounds_sig0[4] = (200, 500)
#     diffstep = [0.001, 10, 10] # differential step to apply to the TRF fitting algorithm, used for computing the finite difference
#     xscale = np.ones(len(diffstep)) # scale factor of the parameters to fit, see least_squares doc for more details
#     bin_bounds0 = [(-0.5, 1.5), (-0.1, 0.4), (-0.1, 0.4), (-0.1, 0.4), (-0.1, 0.4), (0, 2.)] # Boundaries of the histogram, to be set manually after checking the histogram sphape with "skip_fit = True"
    
#     ''' Set the initial conditions '''
#     mu_opd0 = np.array([300, 2400, 2400, 300, -150, 4500]) # initial guess of DeltaPhi mu
#     sig_opd0 = np.array([150, 260, 260, 100, 300, 250]) # initial guess of DeltaPhi sig
#     na0 = np.array([0.3, 0.001, 0.001, 0.1, 0.04, 0.16]) # initial guess of astro null
    
#     ''' Import real data '''
#     datafolder = '20190907/omi_cet_50nm_offset/'
#     darkfolder = '20190907/dark_50nm_offset/'
#     root = "//silo.physics.usyd.edu.au/silo4/snert/"
#     #root = "/mnt/96980F95980F72D3/glint/"
#     file_path = root+'GLINTprocessed/'+datafolder
#     save_path = file_path+'output/'
#     data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'omi_cet' in f][nb_files_data[0]:nb_files_data[1]]
#     dark_list = [root+'GLINTprocessed/'+darkfolder+f for f in os.listdir(root+'GLINTprocessed/'+darkfolder) if '.hdf5' in f and 'dark' in f][nb_files_dark[0]:nb_files_dark[1]]

#    # =============================================================================
#    # omi cet stacked 100 frames - Null1 is inverted, null4 is ok
#    # =============================================================================
#    ''' Set the bounds of the parameters to fit '''
#    bounds_mu0 = [(300, 1000), (2200, 2500), (2200, 2500), (100, 600), (2200, 2500), (2200, 2500)] # bounds for DeltaPhi mu, one tuple per null
#    bounds_sig0 = [(100, 500), (200, 300), (200, 300), (1,120), (50, 200), (200, 300)] # bounds for DeltaPhi sig
#    bounds_na0 = [(0.1, 0.4), (0., 0.05), (0., 0.01), (0., 0.1), (-0.01, 0.1), (0., 0.05)] # bounds for astronull
#    diffstep = [0.001, 10, 10] # differential step to apply to the TRF fitting algorithm, used for computing the finite difference
#    xscale = np.ones(len(diffstep)) # scale factor of the parameters to fit, see least_squares doc for more details
#    bin_bounds0 = [(0., 1), (-0.1, 0.4), (-0.1, 0.4), (0, 0.5), (-0.1, 0.4), (-0.1, 0.4)] # Boundaries of the histogram, to be set manually after checking the histogram sphape with "skip_fit = True"
#    
#    ''' Set the initial conditions '''
#    mu_opd0 = np.array([600, 2400, 2400, 200, 2300, 2300]) # initial guess of DeltaPhi mu
#    sig_opd0 = np.array([250, 260, 260, 8, 100, 201]) # initial guess of DeltaPhi sig
#    na0 = np.array([0.3, 0.001, 0.001, 0.028, 0.001, 0.001]) # initial guess of astro null
#    
#    ''' Import real data '''
#    datafolder = '20190907/omi_cet_stackedframe100/'
#    darkfolder = '20190907/dark_stackedframe100/'
#    root = "//silo.physics.usyd.edu.au/silo4/snert/"
#    #root = "/mnt/96980F95980F72D3/glint/"
#    file_path = root+'GLINTprocessed/'+datafolder
#    save_path = file_path+'output/'
#    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'omi_cet' in f][nb_files_data[0]:nb_files_data[1]]
#    dark_list = [root+'GLINTprocessed/'+darkfolder+f for f in os.listdir(root+'GLINTprocessed/'+darkfolder) if '.hdf5' in f and 'dark' in f][nb_files_dark[0]:nb_files_dark[1]]

#    # =============================================================================
#    # omi cet stacked 10 frames - Null1 is inverted, null4 is ok
#    # =============================================================================
#    ''' Set the bounds of the parameters to fit '''
#    bounds_mu0 = [(300, 1000), (2200, 2500), (2200, 2500), (0, 400), (2200, 2500), (2200, 2500)] # bounds for DeltaPhi mu, one tuple per null
#    bounds_sig0 = [(100, 500), (200, 300), (200, 300), (20,140), (50, 200), (200, 300)] # bounds for DeltaPhi sig
#    bounds_na0 = [(0.1, 0.4), (0., 0.05), (0., 0.01), (0., 0.1), (-0.01, 0.1), (0., 0.05)] # bounds for astronull
#    diffstep = [0.001, 10, 10] # differential step to apply to the TRF fitting algorithm, used for computing the finite difference
#    xscale = np.ones(len(diffstep)) # scale factor of the parameters to fit, see least_squares doc for more details
#    bin_bounds0 = [(0., 1), (-0.1, 0.4), (-0.1, 0.4), (-0.1, 0.4), (-0.1, 0.4), (-0.1, 0.4)] # Boundaries of the histogram, to be set manually after checking the histogram sphape with "skip_fit = True"
#    
#    ''' Set the initial conditions '''
#    mu_opd0 = np.array([600, 2400, 2400, 200, 2300, 2300]) # initial guess of DeltaPhi mu
#    sig_opd0 = np.array([250, 260, 260, 50, 100, 201]) # initial guess of DeltaPhi sig
#    na0 = np.array([0.3, 0.001, 0.001, 0.028, 0.001, 0.001]) # initial guess of astro null
#    
#    ''' Import real data '''
#    datafolder = '20190907/omi_cet_stackedframe10/'
#    darkfolder = '20190907/dark_stackedframe10/'
#    root = "//silo.physics.usyd.edu.au/silo4/snert/"
#    #root = "/mnt/96980F95980F72D3/glint/"
#    file_path = root+'GLINTprocessed/'+datafolder
#    save_path = file_path+'output/'
#    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'omi_cet' in f][nb_files_data[0]:nb_files_data[1]]
#    dark_list = [root+'GLINTprocessed/'+darkfolder+f for f in os.listdir(root+'GLINTprocessed/'+darkfolder) if '.hdf5' in f and 'dark' in f][nb_files_dark[0]:nb_files_dark[1]]

#    # =============================================================================
#    #eps peg - 50 nm - Null1 is inverted, null4 is ok
#    # =============================================================================
#    nulls_to_invert = ['null1'] # If one null and antinull outputs are swapped in the data processing
#    nulls_to_invert_model = ['null1'] # If one null and antinull outputs are swapped in the data processing
#    ''' Set the bounds of the parameters to fit '''
#    bounds_mu0  = [(50, 500),   (2200, 2500), (2200, 2500), (0, wl_mid/4), (-600, 400), (5900, 7000)] # bounds for DeltaPhi mu, one tuple per null
#    bounds_sig0 = [(100, 500),  (200, 300),   (200, 300),   (20,100),      (100, 500),  (100, 400)] # bounds for DeltaPhi sig
#    bounds_na0  = [(-0.2, 0.2), (-0.2, 0.2),   (-0.2, 0.2),   (-0.2, 0.2), (-0.2, 0.2), (-0.2, 0.2)] # bounds for astronull
##    bounds_mu0[4] = (-6600, -5900)
##    bounds_sig0[4] = (200, 500)
#    diffstep = [0.001, 10, 10] # differential step to apply to the TRF fitting algorithm, used for computing the finite difference
#    xscale = np.ones(len(diffstep)) # scale factor of the parameters to fit, see least_squares doc for more details
#    bin_bounds0 = [(-0.5, 1.5), (-0.1, 0.4), (-0.1, 0.4), (-0.5, 1), (-0.5, 1.), (-0.2, 2.)] # Boundaries of the histogram, to be set manually after checking the histogram sphape with "skip_fit = True"
#    
#    ''' Set the initial conditions '''
#    mu_opd0 = np.array([300, 2400, 2400, 300, -150, 6000]) # initial guess of DeltaPhi mu
#    sig_opd0 = np.array([150, 260, 260, 80, 300, 250]) # initial guess of DeltaPhi sig
#    na0 = np.array([-0.001, -0.001, -0.001, -0.001, -0.001, -0.001]) # initial guess of astro null
#    
#    ''' Import real data '''
#    datafolder = '20190907/eps_peg_50nm_offset/'
#    darkfolder = '20190907/dark_50nm_offset/'
#    root = "//silo.physics.usyd.edu.au/silo4/snert/"
#    #root = "/mnt/96980F95980F72D3/glint/"
#    file_path = root+'GLINTprocessed/'+datafolder
#    save_path = file_path+'output/'
#    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'eps_peg' in f][nb_files_data[0]:nb_files_data[1]]
#    dark_list = [root+'GLINTprocessed/'+darkfolder+f for f in os.listdir(root+'GLINTprocessed/'+darkfolder) if '.hdf5' in f and 'dark' in f][nb_files_dark[0]:nb_files_dark[1]]

#    # =============================================================================
#    #eps peg - Null1 is inverted, null4 is ok
#    # =============================================================================
#    ''' Set the bounds of the parameters to fit '''
#    bounds_mu0  = [(0, 500),   (2200, 2500), (2200, 2500), (0, wl_mid/4), (-400, 400), (6250, 7700)] # bounds for DeltaPhi mu, one tuple per null
#    bounds_sig0 = [(50, 450),  (200, 300),   (200, 300),   (50,200),      (100, 500),  (200, 600)] # bounds for DeltaPhi sig
#    bounds_na0  = [(-0.1, 0.1), (-0.2, 0.2),   (-0.2, 0.2),   (-0.1, 0.1), (-0.1, 0.1), (-0.1, 0.1)] # bounds for astronull
##    bounds_mu0[4] = (-6600, -5900)
##    bounds_sig0[4] = (200, 500)
#    diffstep = [0.001, 10, 10] # differential step to apply to the TRF fitting algorithm, used for computing the finite difference
#    xscale = np.ones(len(diffstep)) # scale factor of the parameters to fit, see least_squares doc for more details
#    bin_bounds0 = [(-1., 2.), (-0.1, 0.4), (-0.1, 0.4), (-1, 1.5), (-0.5, 1.), (-0.5, 2.)] # Boundaries of the histogram, to be set manually after checking the histogram sphape with "skip_fit = True"
#    
#    ''' Set the initial conditions '''
#    mu_opd0 = np.array([300, 2400, 2400, 300, -150, 7000]) # initial guess of DeltaPhi mu
#    sig_opd0 = np.array([150, 260, 260, 80, 300, 250]) # initial guess of DeltaPhi sig
#    na0 = np.array([-0.001, -0.001, -0.001, -0.001, -0.001, -0.001]) # initial guess of astro null
#    
#    ''' Import real data '''
#    datafolder = '20190907/eps_peg/'
#    darkfolder = '20190907/dark/'
#    root = "//silo.physics.usyd.edu.au/silo4/snert/"
#    #root = "/mnt/96980F95980F72D3/glint/"
#    file_path = root+'GLINTprocessed/'+datafolder
#    save_path = file_path+'output/'
#    data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'eps_peg' in f][nb_files_data[0]:nb_files_data[1]]
#    dark_list = [root+'GLINTprocessed/'+darkfolder+f for f in os.listdir(root+'GLINTprocessed/'+darkfolder) if '.hdf5' in f and 'dark' in f][nb_files_dark[0]:nb_files_dark[1]]
#
    
    ## =============================================================================
    ##  20200201/RLeo2/
    ## =============================================================================
    #''' Set the bounds of the parameters to fit '''
    #bounds_mu0 = [(-2*wl_mid, 2*wl_mid), (2200, 2500), (2200, 2500), (-1600, -600), (2200, 2500), (2200, 2500)] # bounds for DeltaPhi mu, one tuple per null
    #bounds_sig0 = [(50, 150), (200, 300), (200, 300), (80,150), (150, 250), (200, 300)] # bounds for DeltaPhi sig
    #bounds_na0 = [(0., 0.4), (0., 0.05), (0., 0.01), (0., 0.5), (-0.01, 0.1), (0., 0.05)] # bounds for astronull
    #diffstep = [0.001, 10, 10] # differential step to apply to the TRF fitting algorithm, used for computing the finite difference
    #xscale = np.ones(len(diffstep)) # scale factor of the parameters to fit, see least_squares doc for more details
    #
    #''' Set the initial conditions '''
    #mu_opd0 = np.array([389, 2400, 2400, -1200, 2300, 2300]) # initial guess of DeltaPhi mu
    #sig_opd0 = np.array([100, 260, 260, 110, 200, 201]) # initial guess of DeltaPhi sig
    #na0 = np.array([0.25, 0.001, 0.001, 0.2, 0.001, 0.001]) # initial guess of astro null
    #
    #
    #''' Import real data '''
    #datafolder = '20200201/RLeo2/'
    #darkfolder = '20200201/dark2/'
    #root = "//silo.physics.usyd.edu.au/silo4/snert/"
    ##root = "/mnt/96980F95980F72D3/glint/"
    #file_path = root+'GLINTprocessed/'+datafolder
    #save_path = file_path+'output/'
    #data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'rleo' in f][nb_files_data[0]:nb_files_data[1]]
    #dark_list = [root+'GLINTprocessed/'+darkfolder+f for f in os.listdir(root+'GLINTprocessed/'+darkfolder) if '.hdf5' in f and 'dark' in f][nb_files_dark[0]:nb_files_dark[1]]
    
    ## =============================================================================
    ##  20200201/AlfBoo/
    ## =============================================================================
    #''' Set the bounds of the parameters to fit '''
    #bounds_mu0 = [(-wl_mid, wl_mid), (2200, 2500), (2200, 2500), (-wl_mid, wl_mid), (2200, 2500), (2200, 2500)] # bounds for DeltaPhi mu, one tuple per null
    #bounds_sig0 = [(50, 150), (200, 300), (200, 300), (80,150), (50, 150), (200, 300)] # bounds for DeltaPhi sig
    #bounds_na0 = [(0., 0.1), (0., 0.05), (0., 0.01), (0., 0.1), (-0.01, 0.1), (0., 0.05)] # bounds for astronull
    #diffstep = [0.001, 10, 10] # differential step to apply to the TRF fitting algorithm, used for computing the finite difference
    #xscale = np.ones(len(diffstep)) # scale factor of the parameters to fit, see least_squares doc for more details
    #bin_bounds0 = [(-0.1, 2.), (-0.1, 0.4), (-0.1, 0.4), (-0.1, 2.), (-0.1, 0.4), (-0.1, 0.4)] # Boundaries of the histogram, to be set manually after checking the histogram sphape with "skip_fit = True"
    #
    #''' Set the initial conditions '''
    #mu_opd0 = np.array([389, 2400, 2400, -1200, 2300, 2300]) # initial guess of DeltaPhi mu
    #sig_opd0 = np.array([100, 260, 260, 110, 200, 201]) # initial guess of DeltaPhi sig
    #na0 = np.array([0.25, 0.001, 0.001, 0.2, 0.001, 0.001]) # initial guess of astro null
    #
    #
    #''' Import real data '''
    #datafolder = '20200201/AlfBoo_50nm/'
    #darkfolder = '20200201/dark3_50nm/'
    #root = "//silo.physics.usyd.edu.au/silo4/snert/"
    ##root = "/mnt/96980F95980F72D3/glint/"
    #file_path = root+'GLINTprocessed/'+datafolder
    #save_path = file_path+'output/'
    #data_list = [file_path+f for f in os.listdir(file_path) if '.hdf5' in f and 'AlfBoo' in f][nb_files_data[0]:nb_files_data[1]]
    #dark_list = [root+'GLINTprocessed/'+darkfolder+f for f in os.listdir(root+'GLINTprocessed/'+darkfolder) if '.hdf5' in f and 'dark' in f][nb_files_dark[0]:nb_files_dark[1]]
    
    # =============================================================================
    # Rock 'n roll
    # =============================================================================
    if len(data_list) == 0 or len(dark_list) == 0:
        raise UserWarning('data list or dark list is empty')
        
    calib_params_path = root+'GLINTprocessed/'+'calibration_params/'
    zeta_coeff_path = calib_params_path + 'zeta_coeff.hdf5'
    
    if not os.path.exists(save_path):
        os.makedirs(save_path)
    
    ''' Some constants/useless variables kept for retrocompatibility '''
    dphase_bias = 0. # constant value for corrective phase term
    phase_bias = 0. # Phase of the fringes
        
    # List in dictionary: indexes of null, beam A and beam B, zeta label for antinull, segment id
    null_table = {'null1':[0,[0,1], 'null7'], 'null2':[1,[1,2], 'null8'], 'null3':[2,[0,3], 'null9'], \
                  'null4':[3,[2,3], 'null10'], 'null5':[4,[2,0], 'null11'], 'null6':[5,[3,1], 'null12']}
    
    ''' Specific settings for some configurations '''
    if chi2_map_switch:
        n_samp = int(1e+5) # number of samples per loop
        nloop = 1
     
        
    ''' Fool-proof '''
    if not chi2_map_switch and not skip_fit:
        check_mu =  np.any(mu_opd0 <= np.array(bounds_mu0)[:,0]) or np.any(mu_opd0 >= np.array(bounds_mu0)[:,1])
        check_sig =  np.any(sig_opd0 <= np.array(bounds_sig0)[:,0]) or np.any(sig_opd0 >= np.array(bounds_sig0)[:,1])
        check_null = np.any(na0 <= np.array(bounds_na0)[:,0]) or np.any(na0 >= np.array(bounds_na0)[:,1])
        
        if check_mu or check_sig or check_null:
            raise Exception('Check boundaries: the initial guesses (marked as True) are not between the boundaries (null:%s, mu:%s, sig:%s).'%(check_null, check_mu, check_sig))
        
    total_time_start = time()
    for key in ['null1', 'null4', 'null5', 'null6'][:1]: # Iterate over the null to fit
        # =============================================================================
        # Import data
        # =============================================================================
        print('****************')
        print('Processing %s \n'%key)
        
        plt.ioff()
        
        if key in nulls_to_invert_model:
            switch_invert_null = True
        else:
            switch_invert_null = False    
       
        ''' Load data about the null to fit '''
        dark = gff.load_data(dark_list, (wl_min, wl_max), key, nulls_to_invert)
        data = gff.load_data(data_list, (wl_min, wl_max), key, nulls_to_invert, dark)
            
        wl_scale0 = data['wl_scale'] # Wavelength axis. One histogrm per value in this array will be created. The set of histogram will be fitted at once.
                
        ''' Load the zeta coeff we need. if "wl_bounds" kew is sent, the return zeta coeff are the average over the bandwidth set by the tuple of this key'''
        zeta_coeff = gff.get_zeta_coeff(zeta_coeff_path, wl_scale0, False)
        if not zeta_switch:
            for key in zeta_coeff.keys():
                if key != 'wl_scale':
                    zeta_coeff[key][:] = 1.
        
        ''' Get histograms of intensities and dark current in the pair of photomoetry outputs '''
        idx_null = null_table[key][0] # Select the index of the null output to process
        idx_photo = null_table[key][1] # Select the indexes of the concerned photometries
        key_antinull = null_table[key][2] # Select the index of the antinull output to process
        data_IA, data_IB = data['photo'][0], data['photo'][1] # Set photometries in dedicated variable into specific variables for clarity. A and B are the generic id of the beams for the processed baseiune
        
        zeta_minus_A, zeta_minus_B = zeta_coeff['b%s%s'%(idx_photo[0]+1, key)], zeta_coeff['b%s%s'%(idx_photo[1]+1, key)] # Set zeta coeff linking null and photometric outputs into dedicated variables for clarity
        zeta_plus_A, zeta_plus_B = zeta_coeff['b%s%s'%(idx_photo[0]+1, key_antinull)], zeta_coeff['b%s%s'%(idx_photo[1]+1, key_antinull)] # Set zeta coeff linking antinull and photometric outputs into dedicated variables for clarity
    
           
        # =============================================================================
        # Get CDF of dark and photometries
        # =============================================================================
        ''' Get CDF of dark currents in interferometric outputs for generating random values in the MC function '''
        dark_Iminus_axis = cp.array([np.linspace(dark['Iminus'][i].min(), dark['Iminus'][i].max(), \
                                                 np.size(np.unique(dark['Iminus'][i])), endpoint=False) for i in range(len(wl_scale0))], \
                                                 dtype=cp.float32)
    
        dark_Iminus_cdf = cp.array([cp.asnumpy(gff.computeCdf(dark_Iminus_axis[i], dark['Iminus'][i], 'cdf', True)) \
                                    for i in range(len(wl_scale0))], dtype=cp.float32)
    
        dark_Iplus_axis = cp.array([np.linspace(dark['Iplus'][i].min(), dark['Iplus'][i].max(), \
                                                np.size(np.unique(dark['Iplus'][i])), endpoint=False) for i in range(len(wl_scale0))], \
                                                dtype=cp.float32)
    
        dark_Iplus_cdf = cp.array([cp.asnumpy(gff.computeCdf(dark_Iplus_axis[i], dark['Iplus'][i], 'cdf', True)) \
                                   for i in range(len(wl_scale0))], dtype=cp.float32)
    
    
        ''' Handling photometry: either get the CDF for rv generation or just keep the temporal sequence '''
        injection, spectra = gff.getInjectionAndSpectrum(data_IA, data_IB, wl_scale0)
        
        data_IA_axis = cp.linspace(injection[0].min(), injection[0].max(), np.size(np.unique(injection[0])), dtype=cp.float32)
        cdf_data_IA = gff.computeCdf(data_IA_axis, injection[0], 'cdf', True)
    
        data_IB_axis = cp.linspace(injection[1].min(), injection[1].max(), np.size(np.unique(injection[1])), dtype=cp.float32)
        cdf_data_IB = gff.computeCdf(data_IB_axis, injection[1], 'cdf', True)    
    
    
        # =============================================================================
        # Compute the null
        # =============================================================================
        if activate_spectral_binning:
            Iminus = gff.binning(data['Iminus'], data['Iminus'].shape[0], 0)
            Iplus = gff.binning(data['Iplus'], data['Iplus'].shape[0], 0)
            wl_scale = gff.binning(wl_scale0, wl_scale0.size, 0)
        else:
            Iminus = data['Iminus']
            Iplus = data['Iplus']
            wl_scale = wl_scale0
            
        if key in nulls_to_invert:
            data_null = Iplus / Iminus
        else:
            data_null = Iminus / Iplus
        
        # =============================================================================
        # Compute the histogram        
        # =============================================================================
        print('Compute survival function and error bars')
        bin_bounds = bin_bounds0[idx_null]

        sz = np.array([np.size(d[(d>=bin_bounds[0])&(d<=bin_bounds[1])]) for d in data_null]) # size of the sample of measured null depth.
        sz = np.max(sz) # size of the sample of measured null depth.
    #    sz = 1000**2
        ''' Creation of the x-axis of the histogram (one per wavelength)'''
        null_axis = np.array([np.linspace(bin_bounds[0], bin_bounds[1], int(sz**0.5+1), retstep=False, dtype=np.float32) for i in range(data_null.shape[0])])
        
        null_pdf = []
        null_pdf_err = []
        for wl in range(len(wl_scale)): # Compute the histogram per spectral channel
            ''' Create the histogram (one per wavelegnth) '''
            pdf = np.histogram(data_null[wl], null_axis[wl], density=False)[0]
            pdf_size = np.sum(pdf)
            print('Histogram size=', np.sum(pdf), np.sum(pdf)/data_null[wl].size)
            bin_width = null_axis[wl][1]-null_axis[wl][0]
            pdf = pdf / np.sum(pdf)
            null_pdf.append(pdf)
            
            start = time()
            # pdf_err = gff.getErrorPDF(data_null[wl], data_null_err[wl], null_axis[wl]) # Barnaby's method, tend to underestimate the error
            pdf_err = gff.getErrorBinomNorm(pdf, pdf_size, 1.) # Classic method
            stop = time()
            print('Time PDF error=', stop-start)
            null_pdf_err.append(pdf_err)
                                        
        null_pdf = np.array(null_pdf)
        null_pdf_err = np.array(null_pdf_err)
        
        # =============================================================================
        # Section where the fit is done.        
        # =============================================================================
        ''' Select the bounds of the baseline (null) to process '''
        bounds_mu = bounds_mu0[idx_null]
        bounds_sig = bounds_sig0[idx_null]
        bounds_na = bounds_na0[idx_null]
        # Compile them into a readable tuple called by the TRF algorithm
        bounds_fit = ([bounds_na[0], bounds_mu[0], bounds_sig[0]], 
                      [bounds_na[1], bounds_mu[1], bounds_sig[1]])
        
        chi2_liste = [] # Save the reduced Chi2 of the different basin hop
        popt_liste = [] # Save the optimal parameters of the different basin hop
        uncertainties_liste = [] # Save the errors on fitted parameters of the different basin hop
        init_liste = [] # Save the initial guesses of the different basin hop
        pcov_liste = [] # Save the covariance matrix given by the fitting algorithm of the different basin hop
        termination_liste = [] # Save the termination condition of the different basin hop
        wl_scale_saved = wl_scale.copy()
        start_basin_hoppin = False
        for basin_hopping_count in range(basin_hopping_nloop[0], basin_hopping_nloop[1]):
            if chi2_map_switch:
                sys.stdout = Logger(save_path+'mapping_%s_%02d'%(key, basin_hopping_count)+'.log') # Save the content written in the console into a txt file
            else:
                sys.stdout = Logger(save_path+'basin_hop_%s_%02d'%(key, basin_hopping_count)+'.log') # Save the content written in the console into a txt file
                
            print('-------------')
            print(basin_hopping_count)
            print('-------------')
            print('Fitting '+key)  
            # model fitting initial guess

            ''' Create the set of initial guess for each hop '''
            if start_basin_hoppin or activate_random_init_guesses:
                mu_opd, sig_opd, na = basin_hoppin_values(mu_opd0[idx_null], sig_opd0[idx_null], na0[idx_null], bounds_mu, bounds_sig, bounds_na)
            else:
                mu_opd = mu_opd0[idx_null]
                sig_opd = sig_opd0[idx_null]
                na = na0[idx_null]
                start_basin_hoppin = True

                    
            ''' Model fitting '''
            if not chi2_map_switch:
                guess_na = na
                initial_guess = [guess_na, mu_opd, sig_opd]
                initial_guess = np.array(initial_guess, dtype=np.float32)
                
                if skip_fit:
                    ''' No fit is perforend here, just load the values in the initial guess and compute the histogram'''
                    print('Direct display')
                    count = 0.
                    start = time()
                    out = MCfunction(null_axis, *initial_guess)
                    stop = time()
                    print('Duration:', stop-start)
    #                out = z.reshape(null_cdf.shape)
                    na_opt = na
                    uncertainties = np.zeros(3)
                    popt = (np.array([na, mu_opd, sig_opd]), np.ones((3,3)))
                    chi2 = 1/(null_pdf.size-popt[0].size) * np.sum((null_pdf.ravel() - out)**2/null_pdf_err.ravel()**2)
                    term_status = None
                    print('chi2', chi2)
                
                else:            
                    ''' Fit is done here '''
                    print('Model fitting')    
                    count = 0.
                    init_liste.append(initial_guess)
                    
                    start = time()
                    ''' Save the content of the console generated by this function into a txt file'''
                    with open(save_path+'callfunc_%02d.txt'%(basin_hopping_count), 'w') as fichier:
                        popt = gff.curvefit(MCfunction, null_axis, null_pdf.ravel(), p0=initial_guess, sigma=null_pdf_err.ravel(), 
                                            bounds=bounds_fit, diff_step = diffstep, x_scale=xscale)
                        
                    res = popt[2] # all outputs of the fitting function but optimal parameters and covariance matrix (see scipy.optimize.minimize doc)
                    popt = popt[:2] # Optimal parameters found
                    print('Termination:', res.message) # Termination condition
                    term_status = res.status # Value associated by the termination condition
                    
                    stop = time()
                    print('Termination', term_status)
                    print('Duration:', stop - start)
    
                    out = MCfunction(null_axis, *popt[0]) # Hsigogram computed according to the optimal parameters
                    uncertainties = np.diag(popt[1])**0.5 # Errors on the optimal parameters
                    chi2 = 1/(null_pdf.size-popt[0].size) * np.sum((null_pdf.ravel() - out)**2/null_pdf_err.ravel()**2) # Reduced Chi2
                    print('chi2', chi2)
                    
                    ''' Display in an easy-to-read way this key information (optimal parameters, error and reduced Chi2) '''
                    na_opt = popt[0][0]
                    print('******')
                    print(popt[0])
                    print(uncertainties*chi2**0.5)
                    print(chi2)
                    print('******')
    
                    ''' Save input and the outputs of the fit into a npz file. One per basin hop '''
                    np.savez(save_path+os.path.basename(file_path[:-1])+'_%s_%03d'%(key, basin_hopping_count),
                             chi2=chi2, popt=[na_opt]+[elt for elt in popt[0][1:]], uncertainties=uncertainties, init=[guess_na]+list(initial_guess[1:]),
                                             termination=np.array([term_status]), nsamp=np.array([n_samp]), wl=wl_scale)
                
                chi2_liste.append(chi2)
                popt_liste.append([na_opt]+[elt for elt in popt[0][1:]])
                uncertainties_liste.append(uncertainties)
                termination_liste.append(term_status)
                pcov_liste.append(popt[1])
                
                ''' Display the results of the fit'''
                # Each figure display the histogram of 10 wavelength, if more than 10 are fitted, extra figures are created                    
                wl_idx0 = np.arange(wl_scale.size)
                wl_idx0 = list(gff.divide_chunks(wl_idx0, 10)) # Subset of wavelength displayed in one figure
                
                for wl_idx in wl_idx0:
                    f = plt.figure(figsize=(19.20,10.80))
                    txt3 = '%s '%key+'Fitted values: ' + 'Na$ = %.2E \pm %.2E$, '%(na_opt, uncertainties[0]) + \
                    r'$\mu_{OPD} = %.2E \pm %.2E$ nm, '%(popt[0][1], uncertainties[1]) + \
                    r'$\sigma_{OPD} = %.2E \pm %.2E$ nm,'%(popt[0][2], uncertainties[2])+' Chi2 = %.2E '%(chi2)+'(Last = %.3f s)'%(stop-start)
    #                txt3 = '%s '%key+'Fitted values: ' + 'Na$ = %.2E \pm %.2E$, '%(na_opt, uncertainties[0]) +' Chi2 = %.2E '%(chi2)+'(Last = %.3f s)'%(stop-start)
                    count = 0
                    axs = []
                    for wl in wl_idx[::-1]:
                        if len(wl_idx) > 1:
                            ax = f.add_subplot(5,2,count+1)
                        else:
                            ax = f.add_subplot(1,1,count+1)
                        axs.append(ax)
                        plt.title('%s nm'%wl_scale[wl])
                        plt.errorbar(null_axis[wl][:-1], null_pdf[wl], yerr=null_pdf_err[wl], fmt='.', markersize=5, label='Data')
                        plt.errorbar(null_axis[wl][:-1], out.reshape((wl_scale.size,-1))[wl], fmt='+', markersize=5, lw=5, alpha=0.8, label='Fit')                    
                        plt.grid()
                        plt.legend(loc='best')
                        plt.xlabel('Null depth')
                        plt.ylabel('Frequency')
                        # plt.ylim(1e-8, 10)
                        # plt.xlim(-0.01, 0.5)
                        count += 1
                    plt.tight_layout(rect=[0., 0.05, 1, 1])
                    if len(wl_idx) > 1:
                        axs[0].text(0.5, -7.3, txt3, va='center', transform = axs[0].transAxes, bbox=dict(boxstyle="square", facecolor='white'))
                    else:
                        axs[0].text(0.3, -0.1, txt3, va='center', transform = axs[0].transAxes, bbox=dict(boxstyle="square", facecolor='white'))
                    string = key+'_'+'%03d'%(basin_hopping_count)+'_'+str(wl_min)+'-'+str(wl_max)+'_'+os.path.basename(datafolder[:-1])+'_%s'%int(wl_scale[wl_idx[-1]])
                    if not oversampling_switch: string = string + '_nooversamplinginmodel'
                    if not zeta_switch: string = string + '_nozetainmodel'
                    if not skip_fit: 
                        string = string + '_fit_pdf'
                    plt.savefig(save_path+string+'.png')
                    if basin_hopping_nloop[1]-basin_hopping_nloop[0]>5:
                        plt.close('all')
    
                ''' Plot the histogram of the photometries '''
                ''' Photo A '''
                for wl_idx in wl_idx0:
                    f = plt.figure(figsize=(19.20,10.80))
                    axs = []
                    count = 0
                    for wl in wl_idx[::-1]:
                        histo_IA = np.histogram(data_IA[wl], int(data_IA[wl].size**0.5), density=True)
                        histo_dIA = np.histogram(dark['photo'][0][wl], int(np.size(dark['photo'][0][wl])**0.5), density=True)
                        if len(wl_idx) > 1:
                            ax = f.add_subplot(5,2,count+1)
                        else:
                            ax = f.add_subplot(1,1,count+1)
                        axs.append(ax)
                        plt.title('%s nm'%wl_scale[wl])
                        plt.plot(histo_IA[1][:-1], histo_IA[0], '.', markersize=5, label='P%s'%(null_table[key][1][0]+1))
                        plt.plot(histo_dIA[1][:-1], histo_dIA[0], '.', markersize=5, label='Dark')
                        plt.grid()
                        plt.legend(loc='best')
                        plt.xlabel('Flux')
                        plt.ylabel('Frequency')
                        count += 1
                    plt.tight_layout(rect=[0., 0.05, 1, 1])
                    string = 'P%s'%(null_table[key][1][0]+1)+'_'+key+'_'+'%03d'%(basin_hopping_count)+'_'+str(wl_min)+'-'+str(wl_max)+'_'+os.path.basename(datafolder[:-1])+'_%s'%int(wl_scale[wl_idx[-1]])
                    plt.savefig(save_path+string+'.png')
                    if basin_hopping_nloop[1]-basin_hopping_nloop[0]>1:
                        plt.close('all')
    
                ''' Photo B '''
                for wl_idx in wl_idx0:
                    f = plt.figure(figsize=(19.20,10.80))
                    axs = []
                    count = 0
                    for wl in wl_idx[::-1]:
                        histo_IB = np.histogram(data_IB[wl], int(data_IB[wl].size**0.5), density=True)
                        histo_dIB = np.histogram(dark['photo'][1][wl], int(np.size(dark['photo'][1][wl])**0.5), density=True)
                        if len(wl_idx) > 1:
                            ax = f.add_subplot(5,2,count+1)
                        else:
                            ax = f.add_subplot(1,1,count+1)
                        axs.append(ax)
                        plt.title('%s nm'%wl_scale[wl])
                        plt.plot(histo_IB[1][:-1], histo_IB[0], '.', markersize=5, label='P%s'%(null_table[key][1][1]+1))
                        plt.plot(histo_dIB[1][:-1], histo_dIB[0], '.', markersize=5, label='Dark')
                        plt.grid()
                        plt.legend(loc='best')
                        plt.xlabel('Flux')
                        plt.ylabel('Frequency')
                        count += 1
                    plt.tight_layout(rect=[0., 0.05, 1, 1])
                    string = 'P%s'%(null_table[key][1][1]+1)+'_'+key+'_'+'%03d'%(basin_hopping_count)+'_'+str(wl_min)+'-'+str(wl_max)+'_'+os.path.basename(datafolder[:-1])+'_%s'%int(wl_scale[wl_idx[-1]])
                    plt.savefig(save_path+string+'.png')
                    if basin_hopping_nloop[1]-basin_hopping_nloop[0]>1:
                        plt.close('all')            
            else:
                ''' Map the parameters space '''
                print('Mapping parameters space')
                count = 0
                map_na, step_na = np.linspace(bounds_na[0], bounds_na[1], 10, endpoint=False, retstep=True)
                map_mu_opd, step_mu = np.linspace(bounds_mu[0], bounds_mu[1], 12, endpoint=False, retstep=True)
                map_sig_opd, step_sig = np.linspace(bounds_sig[0], bounds_sig[1], 10, endpoint=False, retstep=True)
                chi2map = []
                start = time()
                for visi in map_na:
                    temp1 = []
                    for o in map_mu_opd:
                        temp2 = []
                        for s in map_sig_opd:
                            parameters = np.array([visi, o, s])
                            out = MCfunction(null_axis, *parameters)
                            value = 1/(null_pdf.size-parameters.size) * np.sum((null_pdf.ravel() - out)**2/null_pdf_err.ravel()**2)                        
                            temp2.append([value, visi, o, s])
                        temp1.append(temp2)
                    chi2map.append(temp1)
                stop = time()
                chi2map = np.array(chi2map)
                print('Duration: %.3f s'%(stop-start))
                
                np.savez(save_path+'chi2map_%s_%03d'%(key, basin_hopping_count), 
                         value=chi2map, na=map_na, mu=map_mu_opd, sig=map_sig_opd, wl=wl_scale)
                
                chi2map2 = chi2map[:,:,:,0]
                chi2map2[np.isnan(chi2map2)] = np.nanmax(chi2map[:,:,:,0])
                argmin = np.unravel_index(np.argmin(chi2map2), chi2map2.shape)
                print('Min in param space', chi2map2.min(), map_na[argmin[0]], map_mu_opd[argmin[1]], map_sig_opd[argmin[2]])
                print('Indexes are:,', argmin)
                fake = chi2map2.copy()
                fake[argmin] = chi2map2.max()
                argmin2 = np.unravel_index(np.argmin(fake), chi2map2.shape)
                print('2nd min in param space', chi2map2[argmin2], map_na[argmin2[0]], map_mu_opd[argmin2[1]], map_sig_opd[argmin2[2]])
                print('Indexes are:,', argmin2)
                
                valmin = np.nanmin(chi2map[:,:,:,0])
                valmax = np.nanmax(chi2map[:,:,:,0])
    
                ''' plot the 3D parameters space '''
                # WARNING: they are in log scale
                plt.figure(figsize=(19.20,10.80))
                for i in range(map_na.size):
                    if i < 10:
                        plt.subplot(5,2,i+1)
                        plt.imshow(np.log10(chi2map[i,:,:,0].T), interpolation='none', origin='lower', aspect='auto', 
                                   extent=[map_mu_opd[0]-step_mu/2, map_mu_opd[-1]+step_mu/2, map_sig_opd[0]-step_sig/2, map_sig_opd[-1]+step_sig/2],
                                   vmin=np.log10(valmin), vmax=np.log10(valmax))
                        plt.colorbar()
                        plt.ylabel('sig opd');plt.xlabel('mu opd')
                        plt.title('Na %s'%map_na[i])
                plt.tight_layout(rect=[0,0,1,0.95])
                plt.suptitle(key)
                plt.savefig(save_path+'chi2map_%s_%03d_mu_vs_sig.png'%(key, basin_hopping_count))
                
                plt.figure(figsize=(19.20,10.80))
                for i in range(map_sig_opd.size):
                    if i < 10:
                        plt.subplot(5,2,i+1)
                        plt.imshow(np.log10(chi2map[:,:,i,0]), interpolation='none', origin='lower', aspect='auto', 
                                   extent=[map_mu_opd[0]-step_mu/2, map_mu_opd[-1]+step_mu/2, map_na[0]-step_na/2, map_na[-1]+step_na/2],
                                   vmin=np.log10(valmin), vmax=np.log10(valmax))
                        plt.colorbar()
                        plt.title('sig %s'%map_sig_opd[i])
                        plt.xlabel('mu opd');plt.ylabel('null depth')
                plt.tight_layout(rect=[0,0,1,0.95])
                plt.suptitle(key)
                plt.savefig(save_path+'chi2map_%s_%03d_null_vs_mu.png'%(key, basin_hopping_count))
                        
                plt.figure(figsize=(19.20,10.80))
                for i, it in zip(range(argmin[1]-5,argmin[1]+5), range(10)):
                    plt.subplot(5,2,it+1)
                    plt.imshow(np.log10(chi2map[:,i,:,0]), interpolation='none', origin='lower', aspect='auto', 
                               extent=[map_sig_opd[0]-step_sig/2, map_sig_opd[-1]+step_sig/2, map_na[0]-step_na/2, map_na[-1]]+step_na/2,
                               vmin=np.log10(valmin), vmax=np.log10(valmax))
                    plt.colorbar()
                    plt.xlabel('sig opd');plt.ylabel('null depth')    
                    plt.title('mu %s'%map_mu_opd[i])
                plt.tight_layout(rect=[0,0,1,0.95])
                plt.suptitle(key)
                plt.savefig(save_path+'chi2map_%s_%03d_null_vs_sig.png'%(key, basin_hopping_count))
                
            sys.stdout.close()
        
        results = {key:[popt_liste, uncertainties_liste, chi2_liste, init_liste, termination_liste, pcov_liste, wl_scale, n_samp]}
        wl_scale = wl_scale_saved

        if not skip_fit and not chi2_map_switch:
            ''' Save the optimal parameters, inputs, fit information of all basin hop in one run '''
            pickle_name = key+'_'+'%03d'%(basin_hopping_count)+'_'+str(wl_min)+'-'+str(wl_max)+'_'+os.path.basename(datafolder[:-1])
            pickle_name = pickle_name+'_pdf'
            pickle_name = pickle_name+'.pkl'
                                               
            with open(save_path+pickle_name, 'wb') as f:
                pickle.dump(results, f)
                
    total_time_stop = time()            
    print('Total time', total_time_stop-total_time_start)
    plt.ion()
    plt.show()
    

    
    print('-- End --')

